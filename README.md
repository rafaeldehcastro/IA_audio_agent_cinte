# Voice Agent AI ğŸ™ï¸ğŸ¤–

Microservicio de voz inteligente con componentes **Agentic AI** que permite interacciones de voz de extremo a extremo usando modelos de OpenAI.

## ğŸ“‹ DescripciÃ³n

Sistema que procesa audio humano, lo transcribe, genera una respuesta inteligente y la convierte de vuelta a voz. Implementa el flujo completo: **ASR â†’ LLM â†’ TTS**.

### Flujo de procesamiento

```
Usuario habla (audio) 
  â†’ ASR (Speech to Text)
  â†’ LLM (Procesamiento inteligente)
  â†’ TTS (Text to Speech)
  â†’ Sistema responde (audio)
```

## ğŸš€ CaracterÃ­sticas

- âœ… **ASR**: TranscripciÃ³n de voz a texto con `gpt-4o-mini-transcribe`
- âœ… **LLM**: Procesamiento inteligente con `gpt-5-nano`
- âœ… **TTS**: SÃ­ntesis de voz con `gpt-4o-mini-tts`
- âœ… **API REST**: FastAPI con documentaciÃ³n OpenAPI automÃ¡tica
- âœ… **Docker**: ContainerizaciÃ³n completa
- âœ… **CI/CD**: Pipeline automatizado con GitHub Actions
- âœ… **Tests**: Cobertura de tests unitarios

## ğŸ› ï¸ Stack TecnolÃ³gico

| Componente | TecnologÃ­a |
|------------|------------|
| Framework | FastAPI 0.104+ |
| IA | OpenAI API (ASR, LLM, TTS) |
| Testing | Pytest + Coverage |
| ContainerizaciÃ³n | Docker + Docker Compose |
| CI/CD | GitHub Actions |
| Deploy | Render / Railway |

## ğŸ“¦ InstalaciÃ³n

### Requisitos previos

- Python 3.11+
- Docker (opcional)
- OpenAI API Key

### InstalaciÃ³n local

1. **Clonar el repositorio**
```bash
git clone https://github.com/rafaeldehcastro/IA_audio_agent_cinte.git
cd IA_audio_agent_cinte
```

2. **Crear entorno virtual**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno**
```bash
cp .env.example .env
# Editar .env y agregar tu OPENAI_API_KEY
```

5. **Ejecutar la aplicaciÃ³n**
```bash
uvicorn app.main:app --reload
```

La API estarÃ¡ disponible en `http://localhost:8000`

### InstalaciÃ³n con Docker

1. **Configurar variables de entorno**
```bash
cp .env.example .env
# Editar .env y agregar tu OPENAI_API_KEY
```

2. **Construir y ejecutar**
```bash
docker-compose up --build
```

La API estarÃ¡ disponible en `http://localhost:8000`

## ğŸ¯ Uso

### Endpoint principal: `/voice-agent`

**POST** - Procesa audio y genera respuesta hablada

**Ejemplo con cURL:**
```bash
curl -X POST "http://localhost:8000/voice-agent" \
  -H "accept: application/json" \
  -H "Content-Type: multipart/form-data" \
  -F "audio=@audio.wav"
```

**Respuesta:**
```json
{
  "transcription": "Hola, Â¿cÃ³mo estÃ¡s?",
  "response_text": "Â¡Hola! Estoy muy bien, gracias por preguntar. Â¿En quÃ© puedo ayudarte?",
  "audio_base64": "//uQxAA...",
  "processing_time": 2.34
}
```

### Otros endpoints

- **GET** `/` - InformaciÃ³n del servicio
- **GET** `/health` - Health check
- **GET** `/docs` - DocumentaciÃ³n Swagger interactiva
- **GET** `/openapi.json` - Schema OpenAPI

### Ejemplo con Python

```python
import requests
import base64

# Enviar audio
with open("audio.wav", "rb") as f:
    files = {"audio": f}
    response = requests.post(
        "http://localhost:8000/voice-agent",
        files=files
    )

result = response.json()
print(f"TranscripciÃ³n: {result['transcription']}")
print(f"Respuesta: {result['response_text']}")

# Guardar audio de respuesta
audio_data = base64.b64decode(result['audio_base64'])
with open("response.mp3", "wb") as f:
    f.write(audio_data)
```

## ğŸ§ª Tests

### Ejecutar tests
```bash
pytest tests/ -v
```

### Tests con cobertura
```bash
pytest tests/ --cov=app --cov-report=html
```

### Tests especÃ­ficos
```bash
pytest tests/test_asr_service.py -v
pytest tests/test_llm_service.py -v
pytest tests/test_tts_service.py -v
pytest tests/test_api.py -v
```

## ğŸ“ Estructura del Proyecto

```
IA_audio_agent_cinte/
â”œâ”€â”€ README.md
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI app principal
â”‚   â”œâ”€â”€ config.py               # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic schemas
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ asr_service.py      # Speech to Text
â”‚   â”‚   â”œâ”€â”€ llm_service.py      # Procesamiento LLM
â”‚   â”‚   â””â”€â”€ tts_service.py      # Text to Speech
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ audio_utils.py      # Utilidades de audio
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_asr_service.py
â”‚   â”œâ”€â”€ test_llm_service.py
â”‚   â”œâ”€â”€ test_tts_service.py
â”‚   â””â”€â”€ test_api.py
â””â”€â”€ docs/
    â””â”€â”€ architecture.md          # DocumentaciÃ³n tÃ©cnica
```

## ğŸ—ï¸ Arquitectura

Para ver la arquitectura detallada del sistema, consultar [docs/architecture.md](docs/architecture.md)

### Componentes principales

1. **API REST (FastAPI)**: Punto de entrada HTTP
2. **ASR Service**: TranscripciÃ³n de audio con `gpt-4o-mini-transcribe`
3. **LLM Service**: Procesamiento con `gpt-5-nano`
4. **TTS Service**: SÃ­ntesis de voz con `gpt-4o-mini-tts`

### Decisiones tÃ©cnicas

- **Modelos econÃ³micos**: Se utilizan los modelos mÃ¡s baratos de OpenAI
  - ASR: $0.003/minuto
  - LLM: $0.05 input / $0.40 output (por 1M tokens)
  - TTS: $0.015/minuto
- **Arquitectura modular**: Servicios separados para facilitar testing y mantenimiento
- **Async/await**: Para operaciones I/O no bloqueantes
- **ValidaciÃ³n robusta**: Pydantic para validaciÃ³n de datos
- **DocumentaciÃ³n automÃ¡tica**: OpenAPI/Swagger integrado

## ğŸ’° Costos Estimados

Por peticiÃ³n tÃ­pica (audio de 1 minuto):
- ASR: $0.003
- LLM: ~$0.0001 (500 tokens)
- TTS: $0.015
- **Total**: ~$0.018 por peticiÃ³n

## ğŸš€ Deployment

### Render

1. Conectar repositorio en Render
2. Configurar variables de entorno: `OPENAI_API_KEY`
3. Deploy automÃ¡tico en cada push a `main`

### Railway

```bash
railway login
railway init
railway up
```

### Fly.io

```bash
fly launch
fly secrets set OPENAI_API_KEY=your_key
fly deploy
```

## ğŸ”§ ConfiguraciÃ³n

Variables de entorno (archivo `.env`):

```env
OPENAI_API_KEY=your_api_key_here
APP_NAME=Voice Agent AI
DEBUG=False
MAX_AUDIO_SIZE_MB=10
ALLOWED_AUDIO_FORMATS=.wav,.mp3
ASR_MODEL=gpt-4o-mini-transcribe
LLM_MODEL=gpt-5-nano
TTS_MODEL=gpt-4o-mini-tts
TTS_VOICE=alloy
```

## ğŸ“ Licencia

Este proyecto es parte de un desafÃ­o tÃ©cnico para CINTE.

## ğŸ‘¨â€ğŸ’» Autor

Rafael de Castro
- GitHub: [@rafaeldehcastro](https://github.com/rafaeldehcastro)
- Email: ghereler113@gmail.com

---

**Nota**: Este es un proyecto de demostraciÃ³n tÃ©cnica que implementa un microservicio de voz inteligente con componentes Agentic AI.
